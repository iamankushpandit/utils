Below are **starter templates** for the 3 control docs you’ll reuse every day with Amazon Q (free tier). They’re designed to stay short and prevent context drift.

---

## 1) `PROJECT_STATE.md` (Starter — keep ≤ 1 page)

```markdown
# PROJECT_STATE.md — Utility Explorer

## Current status (as of YYYY-MM-DD)
- Phase/Day: Day 0 (pre-implementation)
- Repo layout: TBD (monorepo vs two repos)
- Local run: Not yet set up

## What is built
- None

## What is agreed (non-negotiable)
- No invented data (no forecasting/interpolation/imputation)
- No hidden blending across sources
- Every value must include provenance: retrieved_at (+ source_published_at when available)
- Show “No data available” when data is missing
- Local-first, cloud-ready, 12-factor config

## Key artifacts (authoritative)
1) openapi.yaml — API contract
2) DB migrations — schema truth
3) ARCHITECTURE.md — patterns (jobs/plugins/provenance)
4) AI_IMPLEMENTATION_RULES.md — autonomy + anti-hallucination rules

## Decisions made
- Geo levels v1: STATE, COUNTY, PLACE (Place = “city”)
- Copilot: read-only, must return grounded results, can answer cross-layer queries

## Open decisions (must ask before proceeding)
- Repo structure: monorepo vs two repos
- DB choice for local/prod: Postgres (default yes)
- Map boundary format: GeoJSON vs TopoJSON
- Cron parsing dependency for nextRunAt (or return null initially)

## Next planned step
- Day 1: repo scaffolding + docker-compose + API starts + health endpoint

## Validation commands (target)
- docker compose up -d
- curl http://localhost:8080/actuator/health
- npm run dev (UI) [later]
```

---

## 2) `SOURCES.md` (Starter — placeholders + rules)

```markdown
# SOURCES.md — Utility Explorer

This project uses **free public sources** only. We do not invent or forecast data.
If a data point is missing, we display “No data available.”

Each source entry must include:
- Official documentation URL
- Terms/license URL (or explicit statement that it’s not available)
- Update cadence (how often it changes, and how often we check)
- Supported geography levels (STATE/COUNTY/PLACE)
- Supported time granularity (MONTH/YEAR/etc.)
- Units
- Change detection method (etag/last-modified/release id/latest period)
- Notes on known limitations

---

## Source: (placeholder) Electricity Pricing
- Source ID: eia_electricity_price (placeholder)
- Official docs: <TBD>
- Terms/license: <TBD>
- Update cadence: <TBD>
- Geo levels: <TBD>
- Granularity: <TBD>
- Units: <TBD>
- Change detection: <TBD>
- Notes: <TBD>

---

## Source: (placeholder) Broadband Availability
- Source ID: fcc_broadband (placeholder)
- Official docs: <TBD>
- Terms/license: <TBD>
- Update cadence: <TBD>
- Geo levels: <TBD>
- Granularity: <TBD>
- Units: <TBD>
- Change detection: <TBD>
- Notes: <TBD>

---

## Source: (placeholder) Water / Wastewater
- Source ID: <TBD>
- Official docs: <TBD>
- Terms/license: <TBD>
- Update cadence: <TBD>
- Geo levels: <TBD>
- Granularity: <TBD>
- Units: <TBD>
- Change detection: <TBD>
- Notes: <TBD>
```

---

## 3) `DEMO.md` (Starter — will be finalized on Day 14)

````markdown
# DEMO.md — Utility Explorer (Local)

## Goal
Demonstrate the project locally with provenance, transparency, and “no invented data.”

## Prerequisites
- Docker installed
- Node installed (for UI)
- Java installed (for API)

---

## Step 1 — Start backend + database
```bash
docker compose up -d --build
````

Validate:

```bash
curl http://localhost:8080/actuator/health
```

Expected: UP

---

## Step 2 — Start UI

```bash
cd utility-explorer-ui
npm install
npm run dev
```

Open: [http://localhost:5173](http://localhost:5173) (or printed port)

---

## Step 3 — Workflow: Transparency page

* Navigate to `/transparency`
* Confirm it displays:

  * Principles
  * Data Status table from `/api/v1/status/sources`

---

## Step 4 — Workflow: Map + legend + provenance

* Navigate to `/`
* Choose a metric/source/period (if controls exist)
* Confirm:

  * Map renders boundaries
  * Legend renders min/max (if data exists)
  * Provenance shows “Retrieved at …”
  * Missing coverage shows “No data available” (no fabricated fills)

---

## Step 5 — Workflow: Drill into a region

* Click a region (state/county depending on availability)
* Drawer opens:

  * Current value + period + retrieved timestamp
  * Terms/source link
* History chart loads from `/api/v1/timeseries`

---

## Step 6 — Export CSV

* Click Export
* Confirm CSV includes provenance columns:

  * retrievedAt
  * sourcePublishedAt (if available)

---

## Step 7 — Data Status

* Navigate to `/status` (if present)
* Confirm it shows:

  * Last run, last success, next run (or null if not implemented yet)
  * Last error if a source failed

```

---

### Optional (but useful): `README.md` mini-starter?
If you want, I can also provide a **README starter** optimized for a portfolio: “what it does / why it’s trustworthy / how to run / architecture summary”.

Just say: **“yes README too”**.
::contentReference[oaicite:0]{index=0}
```
