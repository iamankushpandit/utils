```markdown
# Utility Explorer — Implementation Rules, Developer Playbook, and AI Autonomy Framework

This document defines **non-negotiable rules**, **decision frameworks**, and **quality gates** for implementing Utility Explorer.  
It is written to support **human developers and AI implementers**, with explicit constraints to prevent hallucination, integrity drift, and inconsistent design.

---

## 1) North Star

Utility Explorer succeeds only if it remains **trustworthy, reproducible, and transparent**.

**Primary success metric:**  
A skeptical user can audit any value shown in the UI and trace it to:
- the original public source,
- when we retrieved it (`retrieved_at`),
- when the source published it (if available, `source_published_at`),
- the geography level and the period,
- and whether it was aggregated (and how).

---

## 2) Non-Negotiable Product Rules (Do Not Break)

### 2.1 Integrity Rules
1. **No data invention**
   - No forecasting, estimation, interpolation, smoothing, or imputation.
   - If data is missing: return “No data available.”
2. **No hidden blending**
   - If multiple sources represent the same metric, we show them separately.
   - No averaging across sources unless the source itself publishes an official composite.
3. **Provenance on every value**
   - Every returned value must include `retrieved_at`.
   - Include `source_published_at` when available.
4. **Aggregation is allowed only if explicit**
   - Any aggregation must be labeled and reproducible (store method + group-by rules).
5. **Free public data only (MVP)**
   - Do not introduce paid datasets or unauthorized scrapes.

### 2.2 UX Truthfulness Rules
1. **Do not imply coverage that doesn’t exist**
   - Drilldown boundaries can show, but values cannot be fabricated.
2. **Timestamp visibility**
   - UI must display at least `retrieved_at` prominently for map and charts.
3. **Source attribution**
   - Show source name + terms link for every metric view.

---

## 3) Engineering Principles (Required)

### 3.1 Local-first, Cloud-ready
- The entire system must run locally via Docker Compose.
- Production hosting must not require code changes—only config changes.

### 3.2 12-Factor + Additional Practices
Required:
- config in env vars (no secrets in git)
- logs to stdout/stderr
- stateless API container
- DB as external backing service (even locally via Docker)

Also required:
- **contract-first API** (OpenAPI is authoritative)
- **idempotent ingestion** (safe to re-run)
- **run logs** (`source_run`) are immutable
- minimal security baseline (CORS, optional API keys for heavy endpoints like util-agent)

---

## 4) Implementation Quality Gates (Definition of Done)

No feature is “done” unless all applicable gates pass:

### 4.1 Data Correctness Gates
- [ ] For each stored fact, unique key prevents duplicates.
- [ ] `retrieved_at` is always stored and returned.
- [ ] Optional `source_published_at` handled correctly when missing.
- [ ] “NO_CHANGE” runs do not write duplicate facts.

### 4.2 Provenance Gates
- [ ] API responses include provenance fields.
- [ ] UI renders retrieved timestamp in map legend and region detail.
- [ ] Exports include provenance columns.

### 4.3 Transparency Gates
- [ ] No “magic” computations in code without documentation.
- [ ] Aggregations (if any) are labeled and documented.

### 4.4 Operational Gates
- [ ] Jobs don’t overlap per source (locking).
- [ ] Failures are recorded; last error surfaces in status endpoint.
- [ ] Health endpoint exists.

---

## 5) Developer Rules (Humans + AI)

### 5.1 General Rules
1. **Follow the documents in this order:**
   1) Requirements
   2) Architecture/LLD
   3) OpenAPI contract
   4) This Playbook
2. **Avoid “clever” shortcuts**
   - Prefer explicit data structures, explicit provenance, explicit coverage logic.
3. **Never silently change a contract**
   - If changing API schema, update OpenAPI first.
4. **No hidden dependencies**
   - No implicit reliance on external services unless documented + configured.

### 5.2 Data Source Rules
- Every source must have:
  - a `source_id`
  - attribution text
  - terms URL (or documented absence)
  - update cadence
  - a “change detection” method
- If a source becomes unreachable or changes schema:
  - mark failure; do not fake success

---

## 6) Decision Framework (Autonomy vs Ask)

This framework decides whether the implementer can proceed independently or must ask for confirmation.

### 6.1 Autonomy Allowed (Proceed Without Asking) if ALL are true
- The choice is **low risk** and **reversible**
- It does not change the integrity rules
- It does not change the OpenAPI contract
- It does not introduce new paid services or external dependencies
- It does not change user-facing definitions (“city”, “latest”, “coverage”)

Examples:
- naming of internal classes/packages
- adding indexes for performance
- adding non-breaking optional fields (with defaults)

### 6.2 Must Ask (Stop and Ask) if ANY are true
- It affects **trust** (data correctness, provenance, aggregation, coverage)
- It changes **API response shapes** or meanings
- It changes what “city” means, or adds new geo types (ZIP, CBSA)
- It introduces **billing, ads, tracking, cookies**
- It introduces new data sources with unclear terms
- It changes time semantics (“latest”, common period logic)
- It needs assumptions about data that are not explicitly documented
- It is non-trivial and hard to reverse (schema migration, major refactor)

### 6.3 “Decision Record” Rule (ADR-lite)
For any “Must Ask” item, create a short decision note:
- What is being decided
- Options considered
- Chosen option and why
- Risks and mitigations

---

## 7) AI Implementer Rules (Anti-Hallucination System)

### 7.1 Anti-Hallucination Rules
1. **No unverifiable claims**
   - The AI cannot claim a data source supports a geo level unless verified in source docs or explicitly specified.
2. **No invented endpoints**
   - Only implement endpoints that exist in OpenAPI.
3. **No invented fields**
   - Only add fields defined in OpenAPI or documented in an agreed change request.
4. **No “best guess” behavior that changes meaning**
   - If a rule is ambiguous, the AI must stop and ask.

### 7.2 “Evidence First” Policy for Sources
When adding a source:
- The AI must capture and record:
  - the official documentation URL
  - update cadence (if specified)
  - exact data granularity and geography supported
  - units
- Store these in `source.notes` or a `SOURCES.md` document.

If evidence is unavailable:
- The AI must not proceed with the source addition.

### 7.3 Safe Defaults
If a design choice is needed and not specified:
- Choose the most conservative, trust-preserving option:
  - prefer “No data” over extrapolation
  - prefer “state-level only” over pretending county exists
  - prefer strict intersection for cross-layer queries

---

## 8) AI Context-Length and “Rest/Reset” Procedure

AI implementations can degrade when context grows too long. To prevent errors:

### 8.1 Chunking Rules (Mandatory)
- Work in **small, atomic changes**:
  - 1 migration file at a time
  - 1 controller + endpoint at a time
  - 1 UI component at a time
- Each chunk must include:
  - what changed
  - why
  - how to validate locally

### 8.2 “Context Exhaustion” Stop Rule
The AI must STOP and request a reset/recap if any occur:
- it can’t accurately recall current schema/contracts
- it is about to modify multiple files with uncertain integration points
- it cannot keep track of route names, config names, or key entities

### 8.3 Reset Protocol
When stopping, AI must produce:
1) A **short recap** of what is already implemented (facts only)
2) A **next-step plan** (max 5 steps)
3) A list of **open questions/unknowns**
4) A list of **files touched** and expected state

Then the AI waits for the user to paste:
- the current OpenAPI file OR
- current schema/migrations OR
- repo snapshot/structure

**Rule:** No further implementation until that recap is confirmed.

---

## 9) “How to Add a New Data Source” Checklist

Before coding:
- [ ] Confirm terms allow public use/redistribution
- [ ] Identify supported geos + time granularity
- [ ] Identify update cadence + change detection method
- [ ] Confirm units and metric mapping

During ingestion design:
- [ ] Create/update `source` record with terms + attribution
- [ ] Create/update `source_config` with cadence
- [ ] Implement check step → returns update token
- [ ] Implement ingest step → normalize to facts
- [ ] Ensure idempotency + unique keys
- [ ] Record `source_run` status + error

After:
- [ ] Update `/sources` and `/coverage`
- [ ] Verify UI shows provenance for new source
- [ ] Add to Transparency page sources list

---

## 10) “How to Add a New Metric” Checklist

- [ ] Metric definition (plain English)
- [ ] Unit + directionality (optional)
- [ ] Supported geos + time granularity
- [ ] Source mapping (one or more)
- [ ] Add to `metric` table
- [ ] Update OpenAPI docs if needed
- [ ] Add UI label and legend behavior

---

## 11) “No Surprises” Coding Standards

### 11.1 Backend
- Validate all inputs (period formats, geo levels)
- Return structured errors (`ErrorResponse`)
- Avoid business logic in controllers; use services
- Use UTC timestamps in storage; UI converts to local if needed

### 11.2 Frontend
- Never “fake” values if missing
- Show explicit “No data available”
- Always show provenance and terms links

---

## 12) When to Pause and Ask Questions (Examples)

You must ask if:
- “Should we treat city as Place or incorporate ZCTA?”
- “Should we keep revisions as versions or overwrite?”
- “Should map omit missing regions or return explicit null entries?”
- “Should Util Agent allow partial results by default?”
- “What is ‘latest’ default for each metric?”

---

## 13) Success Criteria for the Entire Project

The project is successful if:
- It runs locally with one command and behaves consistently.
- It can be deployed to a cheap VPS with no code changes.
- Users can validate every number via timestamps + source links.
- Cross-layer queries never return fabricated results.
- Failures and stale sources are visible in the Status view.

---
```
